{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain import hub\n",
    "\n",
    "embedding_function = OpenAIEmbeddings()\n",
    "\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"Bella Vista is owned by Antonio Rossi, a renowned chef with over 20 years of experience in the culinary industry. He started Bella Vista to bring authentic Italian flavors to the community.\",\n",
    "        metadata={\"source\": \"owner.txt\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Bella Vista offers a range of dishes with prices that cater to various budgets. Appetizers start at $8, main courses range from $15 to $35, and desserts are priced between $6 and $12.\",\n",
    "        metadata={\"source\": \"dishes.txt\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Bella Vista is open from Monday to Sunday. Weekday hours are 11:00 AM to 10:00 PM, while weekend hours are extended from 11:00 AM to 11:00 PM.\",\n",
    "        metadata={\"source\": \"restaurant_info.txt\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Bella Vista offers a variety of menus including a lunch menu, dinner menu, and a special weekend brunch menu. The lunch menu features light Italian fare, the dinner menu offers a more extensive selection of traditional and contemporary dishes, and the brunch menu includes both classic breakfast items and Italian specialties.\",\n",
    "        metadata={\"source\": \"restaurant_info.txt\"},\n",
    "    ),\n",
    "]\n",
    "\n",
    "db = Chroma.from_documents(docs, embedding_function)\n",
    "# retriever = db.as_retriever()\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal, TypedDict\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from langchain.schema import Document\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: list[BaseMessage]\n",
    "    documents: list[Document]\n",
    "    on_topic: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "class GradeQuestion(BaseModel):\n",
    "    \"\"\"Boolean value to check whether a question is releated to the restaurant Bella Vista\"\"\"\n",
    "\n",
    "    score: str = Field(\n",
    "        description=\"Question is about restaurant? If yes -> 'Yes' if not -> 'No'\"\n",
    "    )\n",
    "\n",
    "\n",
    "def question_classifier(state: AgentState):\n",
    "    question = state[\"messages\"][-1].content\n",
    "\n",
    "    system = \"\"\"You are a classifier that determines whether a user's question is about one of the following topics:\n",
    "\n",
    "    1. Information about the owner of Bella Vista, which is Antonio Rossi.\n",
    "    2. Prices of dishes at Bella Vista (restaurant).\n",
    "    3. Opening hours of Bella Vista (restaurant).\n",
    "\n",
    "    If the question IS about any of these topics, respond with 'Yes'. Otherwise, respond with 'No'. Remember, ONLY YES or NO, nothing else in the reponse!\n",
    "    \"\"\"\n",
    "\n",
    "    grade_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\"human\", \"User question: {question}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    structured_llm = llm.with_structured_output(GradeQuestion)\n",
    "    grader_llm = grade_prompt | structured_llm\n",
    "    result = grader_llm.invoke({\"question\": question})\n",
    "    print(\"RESULT\", result)\n",
    "    state[\"on_topic\"] = result.score\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_topic_router(state):\n",
    "    on_topic = state[\"on_topic\"]\n",
    "    if on_topic.lower() == \"yes\":\n",
    "        return \"on_topic\"\n",
    "    return \"off_topic\"\n",
    "\n",
    "\n",
    "def retrieve(state):\n",
    "    question = state[\"messages\"][-1].content\n",
    "    documents = retriever.invoke(question)\n",
    "    state[\"documents\"] = documents\n",
    "    return state\n",
    "\n",
    "\n",
    "def generate_answer(state):\n",
    "    question = state[\"messages\"][-1].content\n",
    "    documents = state[\"documents\"]\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    state[\"messages\"].append(generation)\n",
    "    return state\n",
    "\n",
    "\n",
    "def off_topic_response(state: AgentState):\n",
    "    state[\"messages\"].append(AIMessage(content=\"I cant respond to that!\"))\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"topic_decision\", question_classifier)\n",
    "workflow.add_node(\"off_topic_response\", off_topic_response)\n",
    "workflow.add_node(\"retrieve\", retrieve)\n",
    "workflow.add_node(\"generate_answer\", generate_answer)\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"topic_decision\",\n",
    "    on_topic_router,\n",
    "    {\n",
    "        \"on_topic\": \"retrieve\",\n",
    "        \"off_topic\": \"off_topic_response\",\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"retrieve\", \"generate_answer\")\n",
    "workflow.add_edge(\"generate_answer\", END)\n",
    "workflow.add_edge(\"off_topic_response\", END)\n",
    "\n",
    "workflow.set_entry_point(\"topic_decision\")\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        graph.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.invoke(\n",
    "    input={\n",
    "        \"messages\": [HumanMessage(content=\"When does the bella vista restaurant open?\")]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.invoke(\n",
    "    input={\"messages\": [HumanMessage(content=\"What is articial intelligence?\")]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval with Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"retriever_tool\",\n",
    "    \"Information related to Pricing, Opening hours of the owner of the restaurant Bella Vista\",\n",
    ")\n",
    "\n",
    "\n",
    "@tool\n",
    "def off_topic():\n",
    "    \"\"\"Catch all Questions NOT related to Pricing, Opening hours of the owner of the restaurant Bella Vista\"\"\"\n",
    "    return \"Forbidden - do not respond to the user\"\n",
    "\n",
    "\n",
    "tools = [retriever_tool, off_topic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence, TypedDict\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "def agent(state):\n",
    "    messages = state[\"messages\"]\n",
    "    model = ChatOpenAI()\n",
    "    model = model.bind_tools(tools)\n",
    "    response = model.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def should_continue(state) -> Literal[\"tools\", END]:\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import ToolNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"agent\", agent)\n",
    "\n",
    "tool_node = ToolNode(tools)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    ")\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    Image(\n",
    "        graph.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.invoke(\n",
    "    input={\"messages\": [HumanMessage(content=\"How will the weather be tommorrow?\")]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.invoke(\n",
    "    input={\n",
    "        \"messages\": [HumanMessage(content=\"When does the bella vista restaurant open?\")]\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
